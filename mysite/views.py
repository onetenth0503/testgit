from dotenv import load_dotenv
load_dotenv()

import os
import base64
import re
import requests
import torch
from django.core.files.base import ContentFile
from django.core.files.storage import default_storage
from django.shortcuts import render
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
#from transformers import AutoTokenizer, AutoModelForCausalLM
from diffusers import StableDiffusionPipeline

API_URL = "https://api-inference.huggingface.co/models/dima806/facial_emotions_image_detection"
headers = {"Authorization": "Bearer {os.getenv('HUGGINGFACE_API_TOKEN')}"}

# å®šä¹‰æƒ…ç»ªæ ‡ç­¾åˆ°è¡¨æƒ…ç¬¦å·çš„æ˜ å°„
EMOTION_TO_EMOJI = {
    "angry": "ğŸ˜ ",
    "disgust": "ğŸ¤¢",
    "fear": "ğŸ˜¨",
    "happy": "ğŸ˜„",
    "neutral": "ğŸ˜",
    "sad": "ğŸ˜¢",
    "surprise": "ğŸ˜²"
}

def query(image_data):
    response = requests.post(API_URL, headers=headers, data=image_data)
    return response.json()

@csrf_exempt
def capture_image(request):
    if request.method == 'POST':
        image_data = request.POST.get('image')
        if not image_data:
            return render(request, 'camera.html', {'error': 'No image data received'})
        
        try:
            # è§£ç  base64 å›¾åƒæ•°æ®
            image_data = re.sub('^data:image/.+;base64,', '', image_data)
            image_data = base64.b64decode(image_data)
            
            # ä¸´æ—¶ä¿å­˜å›¾åƒ
            file_name = 'captured_image.png'
            file_path = default_storage.save(file_name, ContentFile(image_data))
            
            # è°ƒç”¨æƒ…ç»ªæ£€æµ‹ API
            result = query(image_data)
            
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            default_storage.delete(file_path)
            
            # å°† JSON ç»“æœè½¬æ¢ä¸ºå¸¦æœ‰è¡¨æƒ…ç¬¦å·çš„æ–‡æœ¬
            if 'error' in result:
                result_text = result['error']
            else:
                # æå–æ‰€æœ‰æƒ…ç»ªæ ‡ç­¾åŠå…¶å¯¹åº”çš„è¡¨æƒ…ç¬¦å·
                result_text = ', '.join([f"{EMOTION_TO_EMOJI.get(emotion['label'], emotion['label'])}: {emotion['score']:.2f}" for emotion in result])
            
            # ä½¿ç”¨ deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B æ¨¡å‹ç”Ÿæˆæè¿°æ–‡æœ¬
            tokenizer = AutoTokenizer.from_pretrained("deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B")
            model = AutoModelForCausalLM.from_pretrained("deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B")
            input_text = f"The detected emotions are {result_text}"
            inputs = tokenizer(input_text, return_tensors="pt")
            outputs = model.generate(inputs.input_ids, max_length=50)
            generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # ä½¿ç”¨ stable-diffusion-v1-5 æ¨¡å‹ç”Ÿæˆå›¾åƒ
            pipe = StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4")
            pipe = pipe.to("cuda" if torch.cuda.is_available() else "cpu")
            image = pipe(generated_text).images[0]
            
            # å°†ç”Ÿæˆçš„å›¾åƒä¿å­˜ä¸ºæ–‡ä»¶
            image_file_path = default_storage.save('generated_image.png', ContentFile(image.tobytes()))
            
            # å°†å›¾åƒæ•°æ®ä¼ é€’å›æ¨¡æ¿
            image_data_url = f"data:image/png;base64,{base64.b64encode(image_data).decode()}"
            generated_image_url = f"data:image/png;base64,{base64.b64encode(image.tobytes()).decode()}"
            
            return render(request, 'camera.html', {
                'message': 'Image uploaded successfully',
                'result': result_text,
                'generated_text': generated_text,
                'image_data_url': image_data_url,
                'generated_image_url': generated_image_url
            })
        except ValueError:
            return render(request, 'camera.html', {'error': 'Invalid image data format'})
    return render(request, 'camera.html')

@csrf_exempt
def capture_audio(request):
    if request.method == 'POST':
        audio_file = request.FILES.get('audio')
        if not audio_file:
            return JsonResponse({'error': 'No audio file received'})

        try:
            # ä¿å­˜éŸ³é »æ–‡ä»¶
            audio_path = default_storage.save('temp.wav', ContentFile(audio_file.read()))

            # é€™è£¡å¯ä»¥æ·»åŠ è™•ç†éŸ³é »æ–‡ä»¶çš„ä»£ç¢¼ï¼Œä¾‹å¦‚æƒ…ç·’åˆ†æç­‰

            # åˆªé™¤è‡¨æ™‚éŸ³é »æ–‡ä»¶
            default_storage.delete(audio_path)

            return JsonResponse({'success': 'Audio captured successfully'})
        except Exception as e:
            return JsonResponse({'error': str(e)})
    return render(request, 'audio.html')